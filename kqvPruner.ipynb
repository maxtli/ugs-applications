{"cells":[{"cell_type":"markdown","source":["## Colab Cells"],"metadata":{"id":"1tPw-AaaBPcg"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GM8AWFgz8-3s","executionInfo":{"status":"ok","timestamp":1720647695933,"user_tz":420,"elapsed":3589,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}},"outputId":"67da0b23-11de-4b12-e714-fce130181d03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"URrYc_rl8-3u","executionInfo":{"status":"ok","timestamp":1720647695933,"user_tz":420,"elapsed":2,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}},"outputId":"83a86764-7cc9-47ca-bea2-0561795d1214"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ugs-applications\n"]}],"source":["%cd /content/drive/MyDrive/ugs-applications/"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfMmvclk8-3v","outputId":"418f13be-a728-4ca3-8be4-d6db97a83848","executionInfo":{"status":"ok","timestamp":1720647718193,"user_tz":420,"elapsed":22261,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformer_lens in /usr/local/lib/python3.10/dist-packages (2.2.0)\n","Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.32.1)\n","Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.14.1)\n","Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n","Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.20.0)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.8.0)\n","Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n","Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.31)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.25.2)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.0.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.7.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.1.99)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.3.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.4)\n","Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.41.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.12.2)\n","Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.17.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.23.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.15.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.9.5)\n","Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.16.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer_lens) (12.5.82)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (2.9.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (67.7.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer_lens) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer_lens) (1.3.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n","Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (0.0.3)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"]}],"source":["!pip3 install transformer_lens\n","!pip3 install seaborn\n","!pip3 install fancy_einsum\n","!pip3 install einops"]},{"cell_type":"markdown","source":["##Imports"],"metadata":{"id":"YCbRKThLBTPo"}},{"cell_type":"code","execution_count":117,"metadata":{"id":"8aoNP4Lv8-3v","executionInfo":{"status":"ok","timestamp":1720651464646,"user_tz":420,"elapsed":379,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}}},"outputs":[],"source":["from utils.training_utils import load_model_data\n","import torch\n","from functools import partial\n","import torch.optim\n","from pruners.Pruner import Pruner\n","from utils.MaskConfig import VertexInferenceConfig\n","from utils.task_datasets import get_task_ds\n","from tqdm import tqdm\n","import pickle\n","from scipy.stats import spearmanr\n","from utils.training_utils import LinePlot\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from pruners.Pruner import Pruner\n","from mask_samplers.AblationMaskSampler import MultiComponentMaskSampler\n","import sys\n","from utils.training_utils import load_model_data, update_means_variances_mixed"]},{"cell_type":"code","source":["del sys.modules[\"mask_samplers.AblationMaskSampler\"]"],"metadata":{"id":"2YvGbc83mWo7","executionInfo":{"status":"ok","timestamp":1720650465983,"user_tz":420,"elapsed":555,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}}},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":["## Pruner Class"],"metadata":{"id":"kwuFgc-_BViB"}},{"cell_type":"code","execution_count":136,"metadata":{"id":"yDWr4Cv58-3w","executionInfo":{"status":"ok","timestamp":1720655401286,"user_tz":420,"elapsed":492,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}}},"outputs":[],"source":["class KQVPruner(Pruner):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs, parallel_inference=True)\n","\n","    def process_null_val(self, node_type, layer_no):\n","        if node_type in [\"attn\", \"k\", \"q\", \"v\"]:\n","            null_val = self.null_vals[node_type][...,layer_no,:,:]\n","        elif node_type == \"mlp\":\n","            null_val = self.null_vals['mlp'][...,layer_no,:]\n","        else:\n","            raise Exception(\"vertex type\")\n","\n","        if self.condition_pos:\n","            # seq_pos x i x n_heads x d_head\n","            diff = self.seq_len - null_val.shape[0]\n","            if diff <= 0:\n","                null_val = null_val[:self.seq_len]\n","            else:\n","                null_val = torch.cat([null_val, null_val[[-1]].expand(diff, *[-1 for _ in null_val.shape[1:]])], dim=0)\n","\n","        return null_val\n","\n","\n","    # attentions: (batch_size + batch_size * n_samples) x seq_len x n_heads x d_model\n","    # constants: n_heads x d_head\n","    # prune mask: (batch_size * n_samples) x n_heads, 0 = prune, 1 = keep\n","    def pruning_hook_attention_all_tokens(self, layer_no,node_type, attentions, hook):\n","        bsz = self.pruning_cfg.batch_size\n","        if self.counterfactual_mode:\n","            # first batch_size are counterfactual, then next batch_size are true\n","            null_val = attentions[:bsz]\n","            bsz = 2 * bsz\n","\n","            if not self.condition_pos:\n","                for i, p in enumerate(self.perms):\n","                    null_val[i,:p.shape[0]] = null_val[i,p]\n","\n","            null_val = null_val.repeat(self.pruning_cfg.n_samples, 1, 1, 1)\n","        else:\n","            null_val = self.process_null_val(node_type, layer_no)\n","\n","        try:\n","            bos_out = attentions[:,[0]].clone().detach()\n","            prune_mask = self.mask_sampler.sampled_mask[node_type][layer_no].unsqueeze(1).unsqueeze(-1)\n","            attentions[bsz:] = (\n","                (prune_mask < 0.001) * (1-prune_mask) * null_val\n","                + (prune_mask >= 0.001) * (1-prune_mask) * null_val.detach()\n","            ) + prune_mask * attentions[bsz:].clone()\n","        except Exception as e:\n","            print(bsz)\n","            print(null_val.shape)\n","            print(attentions.shape)\n","            print(prune_mask.shape)\n","            raise e\n","\n","        # prune_idx = prune_mask.clone()\n","        # attentions[bsz + prune_idx[:,0],:,prune_idx[:,1]] = prune_idx * constants[prune_idx[:,1]]\n","        # return attentions\n","        attentions[:,[0]] = bos_out\n","        return attentions\n","\n","    # attentions: (batch_size + batch_size * n_samples) x seq_len x d_model\n","    # constants: d_model\n","    # prune mask: (batch_size * n_samples), 0 = prune, 1 = keep\n","    def pruning_hook_mlp_all_tokens(self, layer_no, mlp_out, hook):\n","\n","        bsz = self.pruning_cfg.batch_size\n","\n","        if self.counterfactual_mode:\n","            # first batch_size are counterfactual, then next batch_size are true\n","            null_val = mlp_out[:bsz]\n","            bsz = 2 * bsz\n","\n","            if not self.condition_pos:\n","                for i, p in enumerate(self.perms):\n","                    null_val[i,:p.shape[0]] = null_val[i,p]\n","\n","            null_val = null_val.repeat(self.pruning_cfg.n_samples, 1, 1)\n","        else:\n","            null_val = self.process_null_val(\"mlp\", layer_no)\n","\n","        try:\n","            bos_out = mlp_out[:,[0]].clone().detach()\n","            prune_mask = self.mask_sampler.sampled_mask['mlp'][layer_no].unsqueeze(1).unsqueeze(-1)\n","            mlp_out[bsz:] = (\n","                (prune_mask < 0.001) * (1-prune_mask) * null_val\n","                + (prune_mask >= 0.001) * (1-prune_mask) * null_val.detach()\n","            ) + prune_mask * mlp_out[bsz:].clone()\n","\n","            # prune_idx = prune_mask.clone()\n","            # attentions[bsz + prune_idx[:,0],:,prune_idx[:,1]] = prune_idx * constants[prune_idx[:,1]]\n","\n","            # return mlp_out\n","        except Exception as e:\n","            print(mlp_out.shape)\n","            print(prune_mask.shape)\n","            print(null_val.shape)\n","            raise e\n","\n","        mlp_out[:,[0]] = bos_out\n","        return mlp_out\n","\n","    def final_hook_last_token(self, out, hook):\n","        bsz = self.pruning_cfg.batch_size\n","\n","        # remove counterfactuals\n","        if self.counterfactual_mode:\n","            out = out[bsz:]\n","\n","        if self.disable_hooks:\n","            out = out.unsqueeze(0)\n","        else:\n","            out = out.unflatten(0, (-1, bsz))\n","        out = (out * self.last_token_mask.unsqueeze(-1)).sum(dim=2)\n","        return out\n","\n","    def get_patching_hooks(self):\n","        # attention_points_filter = lambda layer_no, name: name == f\"blocks.{layer_no}.attn.hook_result\"\n","        k_points_filter = lambda layer_no, name: name == f\"blocks.{layer_no}.attn.hook_k\"\n","        q_points_filter = lambda layer_no, name: name == f\"blocks.{layer_no}.attn.hook_q\"\n","        v_points_filter = lambda layer_no, name: name == f\"blocks.{layer_no}.attn.hook_v\"\n","        attention_points_filter = lambda layer_no, name: name == f\"blocks.{layer_no}.attn.hook_z\"\n","        mlp_out_filter = lambda layer_no, name: name == f\"blocks.{layer_no}.hook_mlp_out\"\n","        final_embed_filter = lambda name: name == f\"blocks.{n_layers-1}.hook_resid_post\"\n","\n","        n_layers = self.base_model.cfg.n_layers\n","\n","        return {\n","                **{f\"patch_k_{layer_no}\": (partial(k_points_filter, layer_no),\n","                   partial(self.pruning_hook_attention_all_tokens, layer_no, \"k\")\n","                ) for layer_no in range(n_layers)},\n","                **{f\"patch_q_{layer_no}\": (partial(q_points_filter, layer_no),\n","                   partial(self.pruning_hook_attention_all_tokens, layer_no, \"q\")\n","                ) for layer_no in range(n_layers)},\n","                **{f\"patch_v_{layer_no}\": (partial(v_points_filter, layer_no),\n","                   partial(self.pruning_hook_attention_all_tokens, layer_no, \"v\")\n","                ) for layer_no in range(n_layers)},\n","                # **{f\"patch_mlp_{layer_no}\": (partial(mlp_out_filter, layer_no),\n","                #    partial(self.pruning_hook_mlp_all_tokens, layer_no)\n","                # ) for layer_no in range(n_layers)},\n","                \"patch_final\": (final_embed_filter, self.final_hook_last_token)\n","        }"]},{"cell_type":"markdown","source":["## Run Pruner"],"metadata":{"id":"4RmXI3vyjXHQ"}},{"cell_type":"code","source":["import os\n","\n","def run_MCMS(ablation_type = \"mean_agnostic\",\n","              dataset = \"ioi\",\n","              n_samples = 1,\n","              batch_size = 100,\n","              model_name = \"gpt2-small\",\n","              owt_batch_size = 10,\n","              k = 1,\n","              max_batches = 10000,\n","              folder = \"results/mcms\"):\n","\n","  if not os.path.exists(folder):\n","    print(\"Creating Folder\", folder)\n","    os.makedirs(folder)\n","\n","  # init model and tokenizer\n","  device, model, tokenizer, owt_iter = load_model_data(model_name, owt_batch_size)\n","  model.eval()\n","  n_layers = model.cfg.n_layers\n","  n_heads = model.cfg.n_heads\n","\n","  # init pruning configs\n","  pruning_cfg = VertexInferenceConfig(model.cfg, device, folder, init_param=1)\n","  pruning_cfg.batch_size = batch_size\n","  pruning_cfg.n_samples = n_samples\n","  pruning_cfg.k = k\n","  print(\"---------------------------\")\n","  print(\"Pruning Config\")\n","  print(\"---------------------------\")\n","  for k,v in pruning_cfg.__dict__.items():\n","    if k != \"constant_prune_mask\" and k!= \"init_params\":\n","      print(k,\":\",v)\n","\n","  # init ds configs\n","  task_ds = get_task_ds(dataset, pruning_cfg.batch_size, device, ablation_type)\n","\n","  for param in model.parameters():\n","      param.requires_grad = False\n","  print(\"---------------------------\")\n","  print(\"Dataset Config\")\n","  print(\"---------------------------\")\n","  [print(k, \":\", v) for k,v in task_ds.__dict__.items()]\n","  print(\"---------------------------\")\n","\n","  pruner_args = task_ds.get_pruner_args({\"zero\", \"mean\", \"resample\", \"cf_mean\", \"cf\", \"oa\", \"oa_specific\",\"mean_agnostic\"})\n","\n","  # init mask_sampler\n","  mask_sampler = MultiComponentMaskSampler(pruning_cfg)\n","  mask_sampler()\n","  print(\"Attn mask shape per layer\", mask_sampler.sampled_mask[\"attn\"][0].shape)\n","  print(\"MLP mask shape per layer\", mask_sampler.sampled_mask[\"mlp\"][0].shape)\n","\n","  print(\"---------------------------\")\n","  print(\"Starting Evaluation\")\n","  print(\"---------------------------\")\n","\n","  # init vertex pruner\n","  vertex_pruner = KQVPruner(model, pruning_cfg, mask_sampler, **pruner_args)\n","  vertex_pruner.add_patching_hooks()\n","  vertex_pruner.modal_attention.requires_grad = False\n","  vertex_pruner.modal_mlp.requires_grad = False\n","\n","  # init results variables\n","  sampling_optimizer = torch.optim.AdamW(mask_sampler.parameters(), lr=1, weight_decay=0)\n","  head_losses = torch.zeros((n_layers * n_heads * 3,1)).to(device)\n","  head_vars = torch.zeros((n_layers * n_heads * 3,1)).to(device)\n","  n_batches_by_head = torch.zeros_like(head_losses).to(device)\n","  n_samples_by_head = torch.zeros_like(head_losses).to(device)\n","\n","  max_batches = int(max_batches / (batch_size * n_samples))\n","\n","\n","  for no_batches in tqdm(range(vertex_pruner.log.t, max_batches)):\n","      batch, last_token_pos,cf = task_ds.retrieve_batch_cf(tokenizer)\n","      last_token_pos = last_token_pos.int()\n","\n","      sampling_optimizer.zero_grad()\n","\n","      loss = vertex_pruner(batch, last_token_pos,timing = False, print_loss = False)\n","      loss.backward()\n","\n","      atp_losses = torch.cat([ts.grad for ts in mask_sampler.mask_perturb['k']] +\n","                             [ts.grad for ts in mask_sampler.mask_perturb['q']] +\n","                             [ts.grad for ts in mask_sampler.mask_perturb['v']], dim=0).unsqueeze(-1)\n","\n","      batch_n_samples = []\n","      for ts in mask_sampler.sampled_mask['k'] +  mask_sampler.sampled_mask['q'] + mask_sampler.sampled_mask['v']:\n","          batch_n_samples.append((ts < 1-1e-3).sum(dim=0))\n","      batch_n_samples = torch.cat(batch_n_samples, dim=0).unsqueeze(-1)\n","\n","\n","      atp_losses = torch.where(\n","          batch_n_samples > 0,\n","          atp_losses / batch_n_samples * n_samples * batch_size,\n","          0\n","      )\n","\n","\n","      head_losses, head_vars, n_batches_by_head, n_samples_by_head = update_means_variances_mixed(head_losses, head_vars, atp_losses, n_batches_by_head, n_samples_by_head, batch_n_samples)\n","  print(\"---------------------------\")\n","  print(\"Finished Evaluation\")\n","  return head_losses, head_vars, n_batches_by_head, n_samples_by_head"],"metadata":{"id":"bunfGy9Lz76F","executionInfo":{"status":"ok","timestamp":1720655735930,"user_tz":420,"elapsed":408,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["head_losses, head_vars, n_batches_by_head, n_samples_by_head = run_MCMS(max_batches = 100000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgrFdIq90PLp","executionInfo":{"status":"ok","timestamp":1720656066638,"user_tz":420,"elapsed":321370,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}},"outputId":"d2f706cc-4bfb-49f7-9365-599162791d59"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model...\n","Loaded pretrained model gpt2-small into HookedTransformer\n","Loading OWT...\n","Loading OWT data from disk\n","Making DataLoader\n","---------------------------\n","Pruning Config\n","---------------------------\n","device : cuda:0\n","n_layers : 12\n","n_heads : 12\n","folder : results/mcms\n","lamb : None\n","record_every : 100\n","checkpoint_every : 5\n","starting_beta : 0.6666666666666666\n","hard_concrete_endpoints : (-0.1, 1.1)\n","layers_to_prune : [('attn', 0), ('mlp', 0), ('attn', 1), ('mlp', 1), ('attn', 2), ('mlp', 2), ('attn', 3), ('mlp', 3), ('attn', 4), ('mlp', 4), ('attn', 5), ('mlp', 5), ('attn', 6), ('mlp', 6), ('attn', 7), ('mlp', 7), ('attn', 8), ('mlp', 8), ('attn', 9), ('mlp', 9), ('attn', 10), ('mlp', 10), ('attn', 11), ('mlp', 11), ('mlp', 12)]\n","temp_min_reg : 0.001\n","temp_adj_intv : 10\n","temp_avg_intv : 20\n","temp_comp_intv : 200\n","temp_convergence_target : 2000\n","temp_c : 0\n","temp_momentum : 0\n","batch_size : 100\n","n_samples : 1\n","lr : 0.01\n","lr_modes : 0.002\n","k : 1\n","---------------------------\n","Dataset Config\n","---------------------------\n","ds_name : ioi\n","batch_size : 100\n","device : cuda:0\n","ablation_type : mean_agnostic\n","means : None\n","ds : <list_iterator object at 0x7e9d4070dcf0>\n","seed : 0\n","fix_prompt : False\n","---------------------------\n","Attn mask shape per layer torch.Size([100, 12])\n","MLP mask shape per layer torch.Size([100])\n","---------------------------\n","Starting Evaluation\n","---------------------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [05:18<00:00,  3.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["---------------------------\n","Finished Evaluation\n"]}]},{"cell_type":"code","source":["with open(\"atp/ioi/single_component_kqv_losses.pickle\", \"wb\") as f:\n","  pickle.dump(head_losses, f)\n","\n","with open(\"atp/ioi/single_component_kqv_vars.pickle\", \"wb\") as f:\n","  pickle.dump(head_vars, f)\n","\n","with open(\"atp/ioi/single_component_kqv_n_samples_by_head.pickle\", \"wb\") as f:\n","  pickle.dump(n_samples_by_head, f)"],"metadata":{"id":"0ReiIX4R19_D","executionInfo":{"status":"ok","timestamp":1720656083600,"user_tz":420,"elapsed":718,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["model_name = \"gpt2-small\"\n","owt_batch_size = 10\n","batch_size = 10\n","ablation_type = \"mean_agnostic\"\n","dataset = \"ioi\"\n","\n","device, model, tokenizer, owt_iter = load_model_data(model_name, owt_batch_size)\n","model = model.eval()\n","# model.cfg.use_attn_result = True\n","\n","pruning_cfg = VertexInferenceConfig(model.cfg, device, \"./\", init_param=1,batch_size = batch_size)\n","task_ds = get_task_ds(dataset,batch_size, device, ablation_type)\n","pruner_args = task_ds.get_pruner_args({\"zero\", \"mean\", \"resample\", \"cf_mean\", \"cf\", \"oa\", \"oa_specific\",\"mean_agnostic\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3d75a9Ie-UDb","executionInfo":{"status":"ok","timestamp":1720650602562,"user_tz":420,"elapsed":3409,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}},"outputId":"29537ff4-62d6-4ee6-ef01-e3dd904c9394"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n","Loading OWT...\n","Loading OWT data from disk\n","Making DataLoader\n"]}]},{"cell_type":"code","source":["pruning_cfg.init_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaLFUkmVzYjy","executionInfo":{"status":"ok","timestamp":1720651196552,"user_tz":420,"elapsed":385,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}},"outputId":"71bebbcc-f380-4485-8dd7-67ee63d8c6b2"},"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'attn': [tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0'),\n","  tensor([[1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.],\n","          [1.]], device='cuda:0')],\n"," 'mlp': [tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0'),\n","  tensor([1.], device='cuda:0')]}"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["folder = \"./\"\n","pruning_cfg.k =10\n","mask_sampler = MultiComponentMaskSampler(pruning_cfg)\n","pruner = KQVPruner(model, pruning_cfg, mask_sampler, **pruner_args)\n","pruner.add_patching_hooks()\n","batch, last_token_pos,cf = task_ds.retrieve_batch_cf(tokenizer)"],"metadata":{"id":"HS25GTjg-apy","executionInfo":{"status":"ok","timestamp":1720650605450,"user_tz":420,"elapsed":1942,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["pruner(batch,last_token_pos)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuBpDTT6nWR2","executionInfo":{"status":"ok","timestamp":1720650606757,"user_tz":420,"elapsed":4,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}},"outputId":"5b170f10-a17a-4e59-f245-592cbe7bbc5d"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["attention hook layer 0, k\n","attention hook layer 0, q\n","attention hook layer 0, v\n","attention hook layer 1, k\n","attention hook layer 1, q\n","attention hook layer 1, v\n","attention hook layer 2, k\n","attention hook layer 2, q\n","attention hook layer 2, v\n","attention hook layer 3, k\n","attention hook layer 3, q\n","attention hook layer 3, v\n","attention hook layer 4, k\n","attention hook layer 4, q\n","attention hook layer 4, v\n","attention hook layer 5, k\n","attention hook layer 5, q\n","attention hook layer 5, v\n","attention hook layer 6, k\n","attention hook layer 6, q\n","attention hook layer 6, v\n","attention hook layer 7, k\n","attention hook layer 7, q\n","attention hook layer 7, v\n","attention hook layer 8, k\n","attention hook layer 8, q\n","attention hook layer 8, v\n","attention hook layer 9, k\n","attention hook layer 9, q\n","attention hook layer 9, v\n","attention hook layer 10, k\n","attention hook layer 10, q\n","attention hook layer 10, v\n","attention hook layer 11, k\n","attention hook layer 11, q\n","attention hook layer 11, v\n","Cuda time 6.5966081619262695\n","Cuda time 157.95404052734375\n","Cuda time 0.005119999870657921\n","KL: 0.1706642061471939\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":112}]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"collapsed_sections":["1tPw-AaaBPcg","kwuFgc-_BViB"],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU","kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}